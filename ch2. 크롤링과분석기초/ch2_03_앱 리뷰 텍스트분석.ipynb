{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **텍스트마이닝(윤상혁 교수)**\n","## ch2. 웹크롤링과 분석기초\n","## ch2_03. 앱리뷰 텍스트분석\n","\n","\n","---"],"metadata":{"id":"fbsvpljy5Cry"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"980yt21ABDR5"},"outputs":[],"source":["# konlpy 패키지 설치\n","!pip install konlpy"]},{"cell_type":"code","source":["# 필요한 패키지들을 임포트\n","import pandas as pd\n","from konlpy.tag import Okt # konlpy.tag 모듈에서 Okt 클래스를 임포트합니다. 그리고 Okt 클래스의 인스턴스를 okt로 생성\n","okt = Okt()"],"metadata":{"id":"LmMtBoXwBFl9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reviews_df = pd.read_csv('http://scottyoon.cafe24.com/data/reviews_20250101_to_20250609.csv')"],"metadata":{"id":"iTqw6PE-BGlh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hLN9ugmGBH79"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3uE4kFm1V3gh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenizer(text):\n","    morph = okt.pos(text)  # 텍스트를 형태소로 분석하여 품사 정보를 추출하고, morph에 저장\n","    words = []  # 형태소 분석 결과가 저장될 리스트 변수\n","    for word, tag in morph:  # 각 형태소와 해당 형태소의 품사 정보에 대해 반복\n","        if tag in ['Noun']:  # 품사가 '명사'인 경우 선택, 'Adjective', 'Adverb', 'Verb'\n","            if len(word) > 1:  # 단어 길이가 1보다 큰 경우에만 선택\n","                words.append(word)  # 선택된 형용사를 words 리스트에 추가\n","    return words"],"metadata":{"id":"IJ-_RDK7BRIj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text='나는 어제 학교에 갔다'"],"metadata":{"id":"qJukLdszWbrs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zbTK0NTJWgft"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#astype은 자료형 변환 함수, 전처리에 용이하게 str로 변환"],"metadata":{"id":"DB7mdlSCBSiJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# data의 total 컬럼에 형태소 추출함수인 tokenizer함수를 적용함"],"metadata":{"id":"esmalUnbBT4-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zyfJXGEZXYg6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#astype은 자료형 변환 함수, 전처리에 용이하게 str로 변환"],"metadata":{"id":"ea4oxCwFBXwQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","cv = CountVectorizer(max_features=5000, ngram_range=(1, 1))  # CountVectorizer 객체 생성, 최대 5000개의 특성으로 설정, 단일 단어로 구성된 토큰만 고려,\n","#만약 nagrma_range=(1, 2)로 설정하면 단일 단어와 두 개의 연속된 단어 조합(bigram)\n","tdm = cv.fit_transform(reviews_df.content)  # 단어 문서 행렬(TDM) 생성, 'content' 열의 텍스트를 기반으로 행렬을 생성함\n","# cv.fit_transform() 안에 분석할 단어 문서 행렬을 넣어주면 됨. fit은 분석하고자 하는 데이터에 맞게 transform 변환을 하는데 DTM 방식으로 변환함.\n","\n","word_count_tf = pd.DataFrame({'단어': cv.get_feature_names_out(), '빈도': tdm.sum(axis=0).flat})\n","# cv.get_feature_names_out()을 통해 추출된 단어 목록과 tdm.sum(axis=0).flat을 통해 단어별 빈도 합계를 계산하여 데이터프레임 생성\n","\n","word_count_tf = word_count_tf.sort_values('빈도', ascending=False)  # 단어를 빈도를 기준으로 내림차순으로 정렬\n","word_count_tf = word_count_tf.reset_index(drop=True)  # 인덱스 초기화\n","word_count_tf.index = word_count_tf.index + 1  # 인덱스를 1부터 시작하도록 수정\n","print(word_count_tf)\n","word_count_tf.to_csv('빈도.csv', encoding='cp949')  # '빈도.csv'라는 이름으로 데이터를 CSV 파일로 저장"],"metadata":{"id":"zbN79kLpBZHq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 빈도가 2 이상인 행만 필터링\n","\n","\n","\n","\n","# 필터링된 결과를 CSV 파일로 저장 (원하는 경우 파일 이름을 변경할 수 있습니다)\n","\n","\n","# 필터링된 결과 출력\n"],"metadata":{"id":"_zRe8OpeoXZ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from wordcloud import WordCloud\n","import urllib.request\n","\n","font_path = 'malgun.ttf'  # WordCloud에 사용할 폰트 파일 경로\n","font_url = 'https://github.com/leejin-kyu/logistic_sentiment/raw/main/malgun.ttf'  # 폰트 파일 다운로드를 위한 URL\n","urllib.request.urlretrieve(font_url, font_path)  # 폰트 파일을 다운로드하여 지정된 경로에 저장\n","\n","\n","# WordCloud 객체 생성, 배경색을 흰색으로 설정하고 최대 100개의 단어를 포함하도록 설정, 크기는 500x500으로 지정, 폰트 경로를 설정\n","\n","\n","# 단어와 빈도로 이루어진 데이터프레임을 이용하여 단어와 해당 단어의 빈도를 사전 형태로 저장\n","\n","\n","# WordCloud 객체에 단어와 빈도 정보를 입력하여 WordCloud 생성\n","\n","\n","# 생성된 WordCloud 이미지를 출력"],"metadata":{"id":"vEA498qQCOjz"},"execution_count":null,"outputs":[]}]}